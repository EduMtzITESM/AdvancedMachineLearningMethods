{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n",
    "\n",
    "### Team members:\n",
    "\n",
    "+ Emmanuel Francisco González Velázquez - A01364577\n",
    "+ Oscar Israel Lerma Franco - A01380817\n",
    "+ Jesús Mario Martínez Díaz - A01740049\n",
    "+ Eduardo Selim Martínez Mayorga - A01795167\n",
    "+ José Antonio Hernández Hernández\n",
    "\n",
    "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
    "\n",
    "- Objective\n",
    "\n",
    "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
    "\n",
    "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
    "\n",
    "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
    "\n",
    "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
    "    \n",
    "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
    "\n",
    "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
    "\n",
    "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
    "\n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
    "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
    "    - Quality of Markdown documentation\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
    "#DATA_PATH = '/home/pepe/Documents/github_repos/datasets/asl_data'\n",
    "#train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "#valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files are located in the same location as this Jupyter Notebook\n",
    "\n",
    "train_df = pd.read_csv('sign_mnist_train.csv')\n",
    "valid_df = pd.read_csv('sign_mnist_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the `train_df` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     12     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will review the dimensions of each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df.loc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of validation dataset\n",
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the explanatory variables and the target variable will be constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array for target variable for training\n",
    "y_train = np.array(train_df['label']).reshape(-1, 1)\n",
    "\n",
    "# array for target variable for validation\n",
    "y_val = np.array(valid_df['label']).reshape(-1, 1)\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "# array for explanatory variables for training\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "\n",
    "# array for explanatory variables for validation\n",
    "x_val = valid_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will review the dimensions of each array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of train explanatory variables\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of train target variable\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of validation explanatory variables\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of validation target variable\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a function that will allow you to split the previously loaded validation set into valition and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    '''\n",
    "    Input: x - an array\n",
    "    Input: y - an arrya\n",
    "    Input: pct - percetage of training dataset\n",
    "    Input: shuffle - Boolean variable to random ordering of observations\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    # Arroja un error si el núm de renglones no coincide\n",
    "    num_renglones = x.shape[0] # i.e. el número de renglones de x\n",
    "    num_renglones_test = math.ceil(pct*num_renglones)\n",
    "    if shuffle: \n",
    "        idxs = np.arange(num_renglones) #crea un arreglo de 0 a n = num_renglones\n",
    "        np.random.shuffle(idxs) # revuelve el objeto idxs\n",
    "        x_test = x[idxs[0:(num_renglones_test + 1)]] # first random idxs for x\n",
    "        y_test = y[idxs[0:(num_renglones_test + 1)]] # same first random idxs for y\n",
    "        x_val = x[idxs[(num_renglones_test + 1):]] # last random idxs for x\n",
    "        y_val = y[idxs[(num_renglones_test + 1):]] # same last random idxs for y\n",
    "    return(x_val, y_val, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `split_val_test` will be applied to obtain the test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will review the dimensions of each array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3587, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of test explanatory variables\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3585, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of validation explanatory variables\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the row number actually coincides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7172"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape[0] + x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3587, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of test target variable\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3585, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of validation target variable\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the row number actually coincides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7172"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape[0] + y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "### The following code removes 'j' and 'z' ascii lowercase characters\n",
    "### and assign to list\n",
    "\n",
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse `normalise()` function (in `A1a_DL_TC5033.ipynb` file) to center de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    # Normalize the data: subtract the mean and divide by the standard deviation\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the training data\n",
    "x_mean = x_train.mean()\n",
    "\n",
    "# Calculate the standard deviation of the training data\n",
    "x_std = x_train.std()\n",
    "\n",
    "\n",
    "x_test_original = x_test.copy()\n",
    "\n",
    "# Normalize the training data using the mean and standard deviation of the training set\n",
    "# This ensures that the training data will have a mean of 0 and a standard deviation of 1\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "\n",
    "# Normalize the validation data using the same mean and standard deviation from the training set\n",
    "# It's important to use the training mean and std to prevent data leakage\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "\n",
    "# Normalize the test data using the same mean and standard deviation from the training set\n",
    "# This keeps the model evaluation consistent with how it was trained\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the explanatory variables effectively have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6268384e-06, 0.99999946)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    # Reshape the 1D array back to 28x28 before plotting\n",
    "    plt.imshow(image.reshape((28, 28)), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 12\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Randomly sample an index from x_train\n",
    "rnd_idx = np.random.randint(len(y_test))\n",
    "\n",
    "# Correct indexing for y_train\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx,0]}')\n",
    "\n",
    "# Plot corresponding image (x) for y in test dataset\n",
    "plot_number(x_test_original[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    Input: x\n",
    "    Input: y\n",
    "    Output: \n",
    "    '''\n",
    "    # Ensure that the number of samples in x and y are equal\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    \n",
    "    total_data = x.shape[0] # Get the total number of samples\n",
    "    if shuffle:\n",
    "        # Generate an array of indices and shuffle them to randomize the order of samples\n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        \n",
    "        # Reorder x and y according to the shuffled indices\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    \n",
    "    # Return a generator that splits the data into minibatches of size `mb_size`\n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de una nueva clase llamada np_tensor, que hereda de la clase np.ndarray (la clase base de arrays en NumPy).\n",
    "class np_tensor(np.ndarray): \n",
    "    # pass es una palabra clave en Python que indica que no se define ningún método o funcionalidad adicional.\n",
    "    # Esto significa que la clase np_tensor, por ahora, no añade nada nuevo a np.ndarray, \n",
    "    # simplemente hereda todas las propiedades y comportamientos de np.ndarray sin modificaciones.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    # El constructor inicializa la capa lineal con los tamaños de entrada y salida.\n",
    "    # input_size: el número de características de entrada (dimensionalidad del vector de entrada).\n",
    "    # output_size: el número de neuronas o salidas de la capa.\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Inicializa los parámetros de la capa utilizando la inicialización de Kaiming He.\n",
    "        '''\n",
    "        # self.W es la matriz de pesos de la capa, de tamaño (output_size, input_size).\n",
    "        # Se inicializa con una distribución normal (randn) escalada por 1/√(input_size/2) \n",
    "        # para mantener una propagación estable de los gradientes.\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "\n",
    "        # self.b es el vector de bias (sesgo) de la capa, de tamaño (output_size, 1).\n",
    "        # Inicializado con ceros.\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "\n",
    "    # Definimos el método forward, que es llamado automáticamente al utilizar la instancia de la clase\n",
    "    # como una función (por eso se usa __call__).\n",
    "    # X: la entrada a la capa, de tamaño (input_size, batch_size).\n",
    "    def __call__(self, X): \n",
    "        # Calculamos la salida de la capa, Z, aplicando la transformación lineal Z = W @ X + b.\n",
    "        # @ es la operación de multiplicación de matrices en Python.\n",
    "        # W es de tamaño (output_size, input_size) y X es de tamaño (input_size, batch_size),\n",
    "        # lo que da como resultado Z de tamaño (output_size, batch_size).\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z  # Retorna la salida Z\n",
    "\n",
    "    # Definimos el método backward para realizar la retropropagación y calcular los gradientes.\n",
    "    # X: la entrada original a la capa.\n",
    "    # Z: la salida de la capa después de aplicar la transformación lineal.\n",
    "    def backward(self, X, Z):\n",
    "        # Calculamos el gradiente de la entrada (X.grad), propagando el gradiente hacia atrás.\n",
    "        # El gradiente con respecto a X es W.T (la transpuesta de W) multiplicado por Z.grad\n",
    "        # (el gradiente de la pérdida con respecto a la salida Z).\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "\n",
    "        # Calculamos el gradiente con respecto a los pesos (self.W.grad).\n",
    "        # El gradiente de los pesos es Z.grad multiplicado por la transpuesta de X.\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "\n",
    "        # Calculamos el gradiente con respecto al bias (self.b.grad).\n",
    "        # Sumamos Z.grad sobre el eje 1 (es decir, sobre el batch) para obtener el gradiente del bias.\n",
    "        # El parámetro keepdims=True mantiene la dimensión del resultado para que coincida con self.b.\n",
    "        self.b.grad = np.sum(Z.grad, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \n",
    "    # Este método especial '__call__' permite que una instancia de la clase sea llamada como una función.\n",
    "    # Z: La entrada a la función de activación (puede ser un array de NumPy).\n",
    "    def __call__(self, Z):\n",
    "        # La función ReLU devuelve el valor máximo entre 0 y cada elemento de Z.\n",
    "        # Si un elemento en Z es negativo, la salida será 0; si es positivo, la salida será el valor del elemento.\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    # Este método 'backward' implementa la retropropagación para la función ReLU.\n",
    "    # Z: La entrada original a la función de activación.\n",
    "    # A: La salida de la función de activación (después de aplicar ReLU en el forward pass).\n",
    "    def backward(self, Z, A):\n",
    "        # Inicializamos el gradiente de Z con una copia del gradiente de A.\n",
    "        Z.grad = A.grad.copy()\n",
    "\n",
    "        # En la retropropagación, los gradientes a través de la función ReLU solo pasan\n",
    "        # si la entrada original Z es mayor que 0. Si Z es menor o igual a 0, se hace cero el gradiente.\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de una clase llamada Sequential_layers que permite crear y manejar un modelo secuencial de capas.\n",
    "# Este tipo de modelo se utiliza frecuentemente en redes neuronales, donde las capas se apilan de manera secuencial\n",
    "# y cada capa toma la salida de la anterior como su entrada.\n",
    "class Sequential_layers():\n",
    "    \n",
    "    # Constructor de la clase, inicializa el modelo secuencial con una lista de capas.\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        # Almacenamos la lista de capas que se pasarán al modelo.\n",
    "        self.layers = layers\n",
    "        # Variable que contendrá la entrada inicial del modelo (el input 'X').\n",
    "        self.x = None\n",
    "        # Diccionario que almacenará las salidas intermedias (outputs) de cada capa.\n",
    "        # Esto es útil para realizar la retropropagación ya que necesitamos las salidas de cada capa.\n",
    "        self.outputs = {}\n",
    "\n",
    "    # Este método __call__ implementa la propagación hacia adelante (forward pass).\n",
    "    # Permite que la clase pueda ser llamada como una función: model(input) es equivalente a model.__call__(input).\n",
    "    def __call__(self, X):\n",
    "        # Almacenamos la entrada original en self.x. Esto es útil para saber qué input se ha pasado.\n",
    "        self.x = X \n",
    "        \n",
    "        # Guardamos la entrada inicial en el diccionario outputs bajo la clave 'l0', ya que esto representa la capa de entrada.\n",
    "        # Cada clave en el diccionario corresponderá a una capa (l1, l2, l3, etc.) y su salida.\n",
    "        self.outputs['l0'] = self.x\n",
    "        \n",
    "        # Iteramos sobre cada capa en la lista self.layers.\n",
    "        # Enumeramos las capas para tener un índice (i), que comienza en 1.\n",
    "        # El índice es útil para rastrear las salidas de cada capa y guardarlas en el diccionario outputs.\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            # Actualizamos self.x al pasar la entrada por la capa actual.\n",
    "            # La salida de cada capa se convierte en la entrada de la siguiente capa.\n",
    "            self.x = layer(self.x)\n",
    "            \n",
    "            # Guardamos la salida de la capa actual en el diccionario outputs bajo la clave 'l{i}'.\n",
    "            # Esto es necesario para la retropropagación, ya que las salidas intermedias se utilizan para calcular los gradientes.\n",
    "            self.outputs['l'+str(i)] = self.x\n",
    "        \n",
    "        # Al final, devolvemos la salida final del modelo después de haber pasado por todas las capas.\n",
    "        return self.x\n",
    "    \n",
    "    # Método backward implementa la retropropagación para calcular los gradientes de todas las capas.\n",
    "    # Utiliza las salidas almacenadas en self.outputs para calcular los gradientes de cada capa en orden inverso.\n",
    "    def backward(self):\n",
    "        # Recorremos las capas en orden inverso (de la última a la primera) usando reversed().\n",
    "        # La retropropagación necesita empezar desde la salida final y moverse hacia la entrada.\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            # Llamamos al método backward de cada capa.\n",
    "            # Para cada capa, pasamos la salida de la capa actual (outputs['l{i}']) y la salida de la siguiente capa (outputs['l{i+1}']).\n",
    "            # Estos valores son necesarios para calcular los gradientes correctos.\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    \n",
    "    # Método update actualiza los parámetros (pesos y bias) de las capas lineales después de la retropropagación.\n",
    "    # La tasa de aprendizaje (learning_rate) controla la magnitud de los cambios realizados en los parámetros.\n",
    "    def update(self, learning_rate=1e-3):\n",
    "        # Recorremos todas las capas en el modelo secuencial.\n",
    "        for layer in self.layers:\n",
    "            # Verificamos si la capa actual es de tipo ReLU.\n",
    "            # Si la capa es ReLU, no hacemos ninguna actualización porque ReLU no tiene parámetros (ni pesos ni bias).\n",
    "            if isinstance(layer, ReLU):\n",
    "                continue  # Pasamos a la siguiente iteración si es ReLU ya que es la función escalon.\n",
    "            \n",
    "            # Si la capa es de tipo Linear, actualizamos los pesos (W) y los bias (b).\n",
    "            # La actualización de los pesos se hace restando el gradiente multiplicado por la tasa de aprendizaje.\n",
    "            # Esto sigue el algoritmo de gradiente descendente.\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            \n",
    "            # Lo mismo se aplica al bias. Restamos el gradiente del bias multiplicado por la tasa de aprendizaje.\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    \n",
    "    # Método predict realiza una predicción usando el modelo secuencial.\n",
    "    # Toma como entrada X y pasa la entrada a través del forward pass (propagación hacia adelante).\n",
    "    def predict(self, X):\n",
    "        # Realizamos un forward pass llamando al modelo con la entrada X.\n",
    "        output = self.__call__(X)\n",
    "        \n",
    "        # Usamos np.argmax para seleccionar el índice de la clase con mayor valor en la salida.\n",
    "        # np.argmax devuelve el índice del valor más alto, lo cual es útil para tareas de clasificación.\n",
    "        # Esto asume que la última capa del modelo es una capa de salida de clasificación, como softmax.\n",
    "        return np.argmax(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    # x - matriz de predicciones de la red neuronal (salidas de la última capa), de tamaño (n_clases, batch_size)\n",
    "    # y - etiquetas verdaderas (ground truth), vector de tamaño (batch_size)\n",
    "    \n",
    "    # Calculamos el tamaño del batch, es decir, cuántos ejemplos se están procesando en esta pasada\n",
    "    batch_size = x.shape[1]\n",
    "    \n",
    "    # Calculamos las puntuaciones exponenciales de las predicciones.\n",
    "    # Esto es parte del proceso para calcular el softmax, que convierte las puntuaciones en probabilidades.\n",
    "    exp_scores = np.exp(x)\n",
    "    \n",
    "    # Dividimos las puntuaciones exponenciales por la suma de todas las puntuaciones por cada ejemplo en el batch.\n",
    "    # Esto asegura que las probabilidades en cada columna (para cada ejemplo) sumen 1.\n",
    "    probs = exp_scores / exp_scores.sum(axis=0)\n",
    "    \n",
    "    # Hacemos una copia de las probabilidades para devolverlas más tarde como las predicciones.\n",
    "    preds = probs.copy()\n",
    "    \n",
    "    # Costo:\n",
    "    # Seleccionamos las probabilidades correspondientes a las clases verdaderas usando las etiquetas 'y'.\n",
    "    # Esto nos da las probabilidades predichas para la clase correcta en cada ejemplo del batch.\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    \n",
    "    # Calculamos la función de costo utilizando la entropía cruzada.\n",
    "    # Tomamos el logaritmo de las probabilidades predichas para las clases correctas, lo negamos y lo sumamos.\n",
    "    # Luego promediamos el costo dividiendo por el tamaño del batch.\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    \n",
    "    # Calcular los gradientes:\n",
    "    # Restamos 1 de las probabilidades predichas para las clases correctas en cada ejemplo.\n",
    "    # Esto es el gradiente de la función de costo con respecto a las entradas de softmax (dl/dx).\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1\n",
    "    \n",
    "    # Almacenamos los gradientes en 'x.grad', que será utilizado en la retropropagación.\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    # Devolvemos las predicciones (probs) y el costo calculado.\n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar un modelo utilizando gradiente descendente.\n",
    "# model: El modelo que se va a entrenar (por ejemplo, un modelo secuencial de capas).\n",
    "# epochs: El número de épocas, que es el número de veces que todo el conjunto de datos se pasa por la red.\n",
    "# mb_size: El tamaño del minibatch, que es el número de ejemplos que se procesan juntos en cada paso de entrenamiento (por defecto 128).\n",
    "# learning_rate: La tasa de aprendizaje, que controla el tamaño de los pasos de actualización de los parámetros del modelo (por defecto 1e-3).\n",
    "def train(model, epochs, mb_size=128, learning_rate=1e-3):\n",
    "    \n",
    "    # Bucle que itera sobre cada época de entrenamiento.\n",
    "    # En cada época, el modelo ve todo el conjunto de datos una vez.\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Para cada minibatch de datos (x, y), se generan minibatches utilizando la función 'create_minibatches'.\n",
    "        # 'x_train' son los datos de entrenamiento y 'y_train' son las etiquetas de entrenamiento.\n",
    "        # Enumeramos los minibatches, lo que proporciona un índice i para cada minibatch.\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            \n",
    "            # Realizamos la propagación hacia adelante (forward pass) a través del modelo con los datos de entrada 'x'.\n",
    "            # x.T transpone el lote de datos para que las dimensiones sean correctas.\n",
    "            # view(np_tensor) convierte el lote en un tensor de tipo np_tensor.\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            \n",
    "            # Calculamos el costo y las predicciones utilizando softmax con entropía cruzada.\n",
    "            # 'scores' son las salidas del modelo, y 'y' son las etiquetas verdaderas.\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            \n",
    "            # Realizamos la retropropagación (backward pass) para calcular los gradientes de los parámetros del modelo.\n",
    "            model.backward()\n",
    "            \n",
    "            # Actualizamos los parámetros del modelo (pesos y bias) utilizando el gradiente calculado y la tasa de aprendizaje.\n",
    "            model.update(learning_rate)\n",
    "        \n",
    "        # Después de procesar todos los minibatches en una época, imprimimos el costo final y la precisión (accuracy).\n",
    "        # 'accuracy' es una función que calcula la precisión en un conjunto de validación (x_val, y_val).\n",
    "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la precisión (accuracy) del modelo sobre un conjunto de datos.\n",
    "# La precisión se define como el porcentaje de predicciones correctas que el modelo hace en comparación con las etiquetas verdaderas.\n",
    "# x: Los datos de entrada (por ejemplo, imágenes, texto, etc.)\n",
    "# y: Las etiquetas verdaderas correspondientes a los datos (clases correctas).\n",
    "# mb_size: El tamaño de minibatch para dividir los datos y procesarlos en partes más pequeñas.\n",
    "def accuracy(x, y, mb_size):\n",
    "    \n",
    "    # Inicializamos las variables 'correct' y 'total'.\n",
    "    # 'correct' contará cuántas predicciones fueron correctas.\n",
    "    # 'total' contará el número total de ejemplos procesados.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Iteramos sobre los minibatches creados a partir de los datos de entrada 'x' y las etiquetas 'y'.\n",
    "    # 'create_minibatches' divide el conjunto de datos en minibatches de tamaño 'mb_size'.\n",
    "    # El bucle itera sobre cada minibatch y lo pasa al modelo.\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        \n",
    "        # Realizamos la predicción del modelo en los datos del minibatch actual.\n",
    "        # 'x.T' transpone los datos del minibatch para asegurar que las dimensiones sean correctas.\n",
    "        # 'view(np_tensor)' convierte el minibatch en un tensor del tipo 'np_tensor', para que el modelo pueda procesarlo.\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        \n",
    "        # Calculamos cuántas de las predicciones fueron correctas.\n",
    "        # 'np.argmax(pred, axis=0)' selecciona el índice de la clase con mayor probabilidad (la predicción del modelo).\n",
    "        # 'y.squeeze()' elimina cualquier dimensión adicional en 'y' para asegurar que los tamaños coincidan.\n",
    "        # 'np.sum(...)' suma el número de predicciones correctas (donde la predicción del modelo coincide con la etiqueta verdadera).\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        \n",
    "        # Actualizamos el contador 'total' con el número de ejemplos en el minibatch actual.\n",
    "        # 'pred.shape[1]' devuelve el tamaño del minibatch (número de ejemplos en este minibatch).\n",
    "        total += pred.shape[1]\n",
    "    \n",
    "    # Retornamos la precisión (accuracy) calculada como la fracción de predicciones correctas sobre el número total de ejemplos.\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primera configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el modelo utilizando la clase Sequential_layers, que toma una lista de capas como entrada.\n",
    "# En este caso, el modelo consiste en varias capas secuenciales:\n",
    "# 1. Una capa lineal que transforma un vector de 784 dimensiones (por ejemplo, una imagen de 28x28 píxeles) a 200 dimensiones.\n",
    "# 2. Una función de activación ReLU.\n",
    "# 3. Otra capa lineal que transforma las 200 dimensiones a 200 dimensiones.\n",
    "# 4. Otra función de activación ReLU.\n",
    "# 5. Una capa final que transforma las 200 dimensiones a 10, que puede representar 10 clases para un problema de clasificación.\n",
    "model = Sequential_layers([\n",
    "    Linear(784, 512),  # Capa Lineal: 784 -> 512\n",
    "    ReLU(),            # Función de activación ReLU\n",
    "    Linear(512, 256),  # Capa Lineal: 512 -> 256\n",
    "    ReLU(),            # Función de activación ReLU\n",
    "    Linear(256, 128),  # Capa Lineal: 256 -> 128\n",
    "    ReLU(),            # Función de activación ReLU\n",
    "    Linear(128, 24)    # Capa de salida: 128 -> 24 (24 clases para las 24 letras del alfabeto ASL)\n",
    "])\n",
    "# Se define el tamaño del minibatch (mb_size).\n",
    "# El minibatch es un subconjunto de los datos de entrenamiento que se procesan juntos en cada iteración.\n",
    "# En este caso, se usarán minibatches de 512 ejemplos.\n",
    "mb_size = 512\n",
    "\n",
    "# Se define la tasa de aprendizaje (learning_rate), que controla el tamaño de los pasos\n",
    "# que se toman al actualizar los parámetros del modelo (pesos y bias) durante el entrenamiento.\n",
    "# En este caso, se ha establecido una tasa de aprendizaje muy pequeña, 1e-4 (0.0001), lo que significa que los ajustes serán pequeños.\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Se define el número de épocas (epochs), que es el número de veces que todo el conjunto de entrenamiento se pasa por el modelo.\n",
    "# Aquí se ha definido que el modelo entrenará durante 20 épocas, lo que significa que verá los datos de entrenamiento 20 veces.\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo: 1.0391040070884532, accuracy: 0.5350069735006974\n",
      "costo: 0.4226498644386189, accuracy: 0.6764295676429568\n",
      "costo: 0.18377187937207515, accuracy: 0.7132496513249651\n",
      "costo: 0.10816546040800562, accuracy: 0.7400278940027895\n",
      "costo: 0.05900619699687712, accuracy: 0.7525801952580196\n",
      "costo: 0.0463853850281025, accuracy: 0.7587168758716876\n",
      "costo: 0.04023709356453927, accuracy: 0.7634588563458856\n",
      "costo: 0.029482401773780576, accuracy: 0.7656903765690377\n",
      "costo: 0.02315452132160348, accuracy: 0.7693165969316597\n",
      "costo: 0.01749915247634291, accuracy: 0.7718270571827057\n",
      "costo: 0.015540173347032499, accuracy: 0.7748953974895397\n",
      "costo: 0.012719525753311338, accuracy: 0.7737796373779637\n",
      "costo: 0.013244609119418795, accuracy: 0.7785216178521618\n",
      "costo: 0.010937755924509962, accuracy: 0.7799163179916317\n",
      "costo: 0.012455362351002003, accuracy: 0.7807531380753138\n",
      "costo: 0.00968133292734466, accuracy: 0.7818688981868899\n",
      "costo: 0.007660244160856901, accuracy: 0.7810320781032078\n",
      "costo: 0.00861888160300878, accuracy: 0.7821478382147838\n",
      "costo: 0.007627037366608449, accuracy: 0.7843793584379358\n",
      "costo: 0.00639403945969726, accuracy: 0.7857740585774059\n",
      "costo: 0.006596898219465632, accuracy: 0.7857740585774059\n",
      "costo: 0.006555729577492623, accuracy: 0.7863319386331938\n",
      "costo: 0.006653260888057849, accuracy: 0.7874476987447698\n",
      "costo: 0.004859165206391173, accuracy: 0.7857740585774059\n",
      "costo: 0.005755677713115717, accuracy: 0.7882845188284519\n",
      "costo: 0.004671292626951677, accuracy: 0.7874476987447698\n",
      "costo: 0.0043845752753594106, accuracy: 0.7880055788005579\n",
      "costo: 0.004513874195388901, accuracy: 0.7882845188284519\n",
      "costo: 0.004190193410597422, accuracy: 0.7885634588563459\n",
      "costo: 0.004209243072352217, accuracy: 0.7885634588563459\n"
     ]
    }
   ],
   "source": [
    "# Se entrena el modelo\n",
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7839420128240869\n"
     ]
    }
   ],
   "source": [
    "# Accuracy del modelo\n",
    "print(accuracy(x_test, y_test, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segunda configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el modelo utilizando la clase Sequential_layers, que toma una lista de capas como entrada.\n",
    "# En este caso, el modelo consiste en varias capas secuenciales:\n",
    "# 1. Una capa lineal que transforma un vector de 784 dimensiones (por ejemplo, una imagen de 28x28 píxeles) a 200 dimensiones.\n",
    "# 2. Una función de activación ReLU.\n",
    "# 3. Otra capa lineal que transforma las 200 dimensiones a 200 dimensiones.\n",
    "# 4. Otra función de activación ReLU.\n",
    "# 5. Una capa final que transforma las 200 dimensiones a 10, que puede representar 10 clases para un problema de clasificación.\n",
    "model_2 = Sequential_layers([\n",
    "    Linear(784, 200),  # Capa Lineal: 784 -> 200\n",
    "    ReLU(),            # Función de activación ReLU\n",
    "    Linear(200,200),  # Capa Lineal: 200 -> 200\n",
    "    ReLU(),            # Función de activación ReLU\n",
    "    Linear(200, 24)    # Capa de salida: 200 -> 24 (24 clases para las 24 letras del alfabeto ASL)\n",
    "])\n",
    "# Se define el tamaño del minibatch (mb_size).\n",
    "# El minibatch es un subconjunto de los datos de entrenamiento que se procesan juntos en cada iteración.\n",
    "# En este caso, se usarán minibatches de 128 ejemplos.\n",
    "mb_size_2 = 128\n",
    "\n",
    "# Se define la tasa de aprendizaje (learning_rate), que controla el tamaño de los pasos\n",
    "# que se toman al actualizar los parámetros del modelo (pesos y bias) durante el entrenamiento.\n",
    "# En este caso, se ha establecido una tasa de aprendizaje muy pequeña, 3e-3 (0.003), lo que significa que los ajustes serán pequeños.\n",
    "learning_rate_2 = 3e-3\n",
    "\n",
    "# Se define el número de épocas (epochs), que es el número de veces que todo el conjunto de entrenamiento se pasa por el modelo.\n",
    "# Aquí se ha definido que el modelo entrenará durante 30 épocas, lo que significa que verá los datos de entrenamiento 20 veces.\n",
    "epochs_2 = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo: 0.010807852895519523, accuracy: 0.7885634588563459\n",
      "costo: 0.003006304250405289, accuracy: 0.7885634588563459\n",
      "costo: 0.0021557037576543847, accuracy: 0.7885634588563459\n",
      "costo: 0.001331516363639432, accuracy: 0.7885634588563459\n",
      "costo: 0.0014983691396088003, accuracy: 0.7885634588563459\n",
      "costo: 0.0009926449510923856, accuracy: 0.7885634588563459\n",
      "costo: 0.00035961372555278067, accuracy: 0.7885634588563459\n",
      "costo: 0.0006989829598673722, accuracy: 0.7885634588563459\n",
      "costo: 0.0004753038175633592, accuracy: 0.7885634588563459\n",
      "costo: 0.0005263885251621068, accuracy: 0.7885634588563459\n",
      "costo: 0.00046293342932331454, accuracy: 0.7885634588563459\n",
      "costo: 0.000407951669291133, accuracy: 0.7885634588563459\n",
      "costo: 0.00044377328061292527, accuracy: 0.7885634588563459\n",
      "costo: 0.00026118037010673114, accuracy: 0.7885634588563459\n",
      "costo: 0.00028317392215635134, accuracy: 0.7885634588563459\n",
      "costo: 0.00014828286043688232, accuracy: 0.7885634588563459\n",
      "costo: 0.0002937856252066253, accuracy: 0.7885634588563459\n",
      "costo: 0.0002100662890743517, accuracy: 0.7885634588563459\n",
      "costo: 0.00023305007099933683, accuracy: 0.7885634588563459\n",
      "costo: 0.0001727842762058107, accuracy: 0.7885634588563459\n",
      "costo: 0.0002898665206627898, accuracy: 0.7885634588563459\n",
      "costo: 0.00014567896947526704, accuracy: 0.7885634588563459\n",
      "costo: 9.785635685619708e-05, accuracy: 0.7885634588563459\n",
      "costo: 0.00017476203658166737, accuracy: 0.7885634588563459\n",
      "costo: 0.00016472711859108155, accuracy: 0.7885634588563459\n",
      "costo: 0.00013574474217379373, accuracy: 0.7885634588563459\n",
      "costo: 0.00014139141831992838, accuracy: 0.7885634588563459\n",
      "costo: 0.000161334078576705, accuracy: 0.7885634588563459\n",
      "costo: 0.00012304284705983392, accuracy: 0.7885634588563459\n",
      "costo: 0.00016891833910213472, accuracy: 0.7885634588563459\n"
     ]
    }
   ],
   "source": [
    "# Se entrena el modelo\n",
    "train(model_2, epochs_2, mb_size_2, learning_rate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7839420128240869\n"
     ]
    }
   ],
   "source": [
    "# Accuracy del modelo\n",
    "print(accuracy(x_test, y_test, mb_size_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because its accuracy is better, we choose model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model on Random data from your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor predicho es: n, el valor real es:n\n"
     ]
    }
   ],
   "source": [
    "# First trial\n",
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test[idx])\n",
    "pred = model_2.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'El valor predicho es: {alphabet[pred]}, el valor real es:{alphabet[y_test[idx].tolist()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor predicho es: e, el valor real es:e\n"
     ]
    }
   ],
   "source": [
    "# Second trial\n",
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test[idx])\n",
    "pred = model_2.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'El valor predicho es: {alphabet[pred]}, el valor real es:{alphabet[y_test[idx].tolist()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor predicho es: d, el valor real es:d\n"
     ]
    }
   ],
   "source": [
    "# Third trial\n",
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test[idx])\n",
    "pred = model_2.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'El valor predicho es: {alphabet[pred]}, el valor real es:{alphabet[y_test[idx].tolist()[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters in fully connected neural networks are critical as they directly influence the model’s performance, learning capacity, and generalization ability. These include learning rate, which controls how quickly the model adjusts weights; batch size, which impacts the stability and speed of training; and the number of hidden layers and neurons, which affect the model's complexity and ability to capture patterns. Proper tuning of these hyperparameters is essential for preventing underfitting, overfitting, and ensuring efficient training. Finding the optimal balance often requires experimentation and techniques like grid search, random search, or automated hyperparameter optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
